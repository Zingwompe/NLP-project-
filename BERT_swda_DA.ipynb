{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33309551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gguaquiere\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68f7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450cc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e604abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36ef6d",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f05991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_val_data(name_dataset : str):\n",
    "\n",
    "    data = load_dataset('silicone',name_dataset)\n",
    "    train = pd.DataFrame(data['train'])\n",
    "    test = pd.DataFrame(data['test'])\n",
    "    val = pd.DataFrame(data['validation'])\n",
    "\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a470024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset silicone (C:\\Users\\gguaquiere\\.cache\\huggingface\\datasets\\silicone\\swda\\1.0.0\\af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 42.93it/s]\n"
     ]
    }
   ],
   "source": [
    "swda_train, swda_test, swda_val = load_train_test_val_data(\"swda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461abdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "swda_train.Dialogue_Act.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "swda_train = swda_train[swda_train.Dialogue_Act.isin(['sd',\n",
    "                                                               'b',\n",
    "                                                               'sv_fx',\n",
    "                                                               '+',\n",
    "                                                               '%'])]\n",
    "\n",
    "swda_test = swda_test[swda_test.Dialogue_Act.isin(['sd',\n",
    "                                                               'b',\n",
    "                                                               'sv_fx',\n",
    "                                                               '+',\n",
    "                                                               '%'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = swda_train[['Utterance','Dialogue_Act']]\n",
    "test = swda_test[['Utterance','Dialogue_Act']]\n",
    "val = swda_val[['Utterance','Dialogue_Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"model\", exist_ok=True)\n",
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    "bert_ckpt_dir = 'model/uncased_L-12_H-768_A-12'\n",
    "bert_ckpt_file = 'model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "bert_config_file = 'model/uncased_L-12_H-768_A-12/bert_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de382852",
   "metadata": {},
   "source": [
    "# **Input Text Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c14d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    \n",
    "    text_column = \"Utterance\"\n",
    "    label_column = \"Dialogue_Act\"\n",
    "\n",
    "    def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = 0\n",
    "        self.classes = classes\n",
    "\n",
    "        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self.prepare_data, [train, test])\n",
    "\n",
    "        print(\"max seq_len\", self.max_seq_len)\n",
    "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "        self.train_x, self.test_x = map(self.data_padding, [self.train_x, self.test_x])\n",
    "\n",
    "    def prepare_data(self, df):\n",
    "        x, y = [], []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows()):\n",
    "            text, label = row[DataPreparation.text_column], row[DataPreparation.label_column]\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "            x.append(token_ids)\n",
    "            y.append(self.classes.index(label))\n",
    "\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def data_padding(self, ids):\n",
    "        x = []\n",
    "        for input_ids in ids:\n",
    "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "            x.append(np.array(input_ids))\n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a81a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=bert_ckpt_dir+\"/vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b800b5",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_defination(max_seq_len, bert_ckpt_file):\n",
    "    \n",
    "    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read())\n",
    "        bert_params = map_stock_config_to_params(bc)\n",
    "        bert_params.adapter_size = None\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "    input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "\n",
    "    print(\"bert shape\", bert_output.shape)\n",
    "\n",
    "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "    logits = keras.layers.Dropout(0.5)(logits)\n",
    "    logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
    "\n",
    "    model = keras.Model(inputs=input_ids, outputs=logits)\n",
    "    model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "    load_stock_weights(bert, bert_ckpt_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce39f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.Dialogue_Act.unique().tolist()\n",
    "\n",
    "data = DataPreparation(train, test, tokenizer, classes, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd31c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_defination(data.max_seq_len, bert_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(1e-5),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f80232",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  x=data.train_x, \n",
    "  y=data.train_y,\n",
    "  validation_split=0.1,\n",
    "  batch_size=16,\n",
    "  shuffle=True,\n",
    "  epochs=3,\n",
    "  #callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82de54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
