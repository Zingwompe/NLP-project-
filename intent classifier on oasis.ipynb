{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33309551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gguaquiere\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68f7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450cc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e604abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36ef6d",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f05991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_val_data(name_dataset : str):\n",
    "\n",
    "    data = load_dataset('silicone',name_dataset)\n",
    "    train = pd.DataFrame(data['train'])\n",
    "    test = pd.DataFrame(data['test'])\n",
    "    val = pd.DataFrame(data['validation'])\n",
    "\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a470024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset silicone (C:\\Users\\gguaquiere\\.cache\\huggingface\\datasets\\silicone\\oasis\\1.0.0\\af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 279.51it/s]\n"
     ]
    }
   ],
   "source": [
    "oasis_train, oasis_test, oasis_val = load_train_test_val_data(\"oasis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b27eb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inform                  2422\n",
       "ackn                    1621\n",
       "reqInfo                 1141\n",
       "backch                   902\n",
       "answ                     677\n",
       "init                     626\n",
       "thank                    621\n",
       "greet                    432\n",
       "answElab                 376\n",
       "accept                   373\n",
       "informIntent             341\n",
       "bye                      335\n",
       "direct                   323\n",
       "confirm                  284\n",
       "expressRegret            213\n",
       "hold                     178\n",
       "expressOpinion           144\n",
       "offer                    129\n",
       "echo                     107\n",
       "appreciate                90\n",
       "refer                     81\n",
       "suggest                   81\n",
       "reqDirect                 74\n",
       "negate                    73\n",
       "exclaim                   68\n",
       "pardon                    68\n",
       "identifySelf              60\n",
       "expressPossibility        56\n",
       "raiseIssue                30\n",
       "expressWish               28\n",
       "reqModal                  20\n",
       "correct                   15\n",
       "directElab                14\n",
       "complete                  13\n",
       "refuse                    12\n",
       "informDisc                11\n",
       "informIntent-hold         11\n",
       "informCont                10\n",
       "selfTalk                   7\n",
       "correctSelf                7\n",
       "expressRegret-inform       1\n",
       "thank-identifySelf         1\n",
       "Name: Dialogue_Act, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oasis_train.Dialogue_Act.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e7860d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e983f374794d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on réduit la taille du dataset pour avoir un temps d'entraînement raisonnable\n",
    "\n",
    "train = oasis_train[['Utterance','Dialogue_Act']]\n",
    "test = oasis_test[['Utterance','Dialogue_Act']]\n",
    "val = oasis_val[['Utterance','Dialogue_Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"model\", exist_ok=True)\n",
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    "bert_ckpt_dir = 'model/uncased_L-12_H-768_A-12'\n",
    "bert_ckpt_file = 'model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "bert_config_file = 'model/uncased_L-12_H-768_A-12/bert_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de382852",
   "metadata": {},
   "source": [
    "# **Input Text Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c14d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    \n",
    "    text_column = \"Utterance\"\n",
    "    label_column = \"Dialogue_Act\"\n",
    "\n",
    "    def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = 0\n",
    "        self.classes = classes\n",
    "\n",
    "        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self.prepare_data, [train, test])\n",
    "\n",
    "        print(\"max seq_len\", self.max_seq_len)\n",
    "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "        self.train_x, self.test_x = map(self.data_padding, [self.train_x, self.test_x])\n",
    "\n",
    "    def prepare_data(self, df):\n",
    "        x, y = [], []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows()):\n",
    "            text, label = row[DataPreparation.text_column], row[DataPreparation.label_column]\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "            x.append(token_ids)\n",
    "            y.append(self.classes.index(label))\n",
    "\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def data_padding(self, ids):\n",
    "        x = []\n",
    "        for input_ids in ids:\n",
    "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "            x.append(np.array(input_ids))\n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a81a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=bert_ckpt_dir+\"/vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b800b5",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_defination(max_seq_len, bert_ckpt_file):\n",
    "    \n",
    "    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read())\n",
    "        bert_params = map_stock_config_to_params(bc)\n",
    "        bert_params.adapter_size = None\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "    input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "\n",
    "    print(\"bert shape\", bert_output.shape)\n",
    "\n",
    "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "    logits = keras.layers.Dropout(0.5)(logits)\n",
    "    logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
    "\n",
    "    model = keras.Model(inputs=input_ids, outputs=logits)\n",
    "    model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "    load_stock_weights(bert, bert_ckpt_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce39f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.Dialogue_Act.unique().tolist()\n",
    "\n",
    "data = DataPreparation(train, test, tokenizer, classes, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd31c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_defination(data.max_seq_len, bert_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(1e-5),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f80232",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  x=data.train_x, \n",
    "  y=data.train_y,\n",
    "  validation_split=0.1,\n",
    "  batch_size=16,\n",
    "  shuffle=True,\n",
    "  epochs=3,\n",
    "  #callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82de54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
