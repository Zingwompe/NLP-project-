{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d411cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gguaquiere\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b15c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b5989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1118d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886cced",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83417f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_val_data(name_dataset : str):\n",
    "\n",
    "    data = load_dataset('silicone',name_dataset)\n",
    "    train = pd.DataFrame(data['train'])\n",
    "    test = pd.DataFrame(data['test'])\n",
    "    val = pd.DataFrame(data['validation'])\n",
    "\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0803891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset silicone (C:\\Users\\gguaquiere\\.cache\\huggingface\\datasets\\silicone\\meld_s\\1.0.0\\af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 598.56it/s]\n"
     ]
    }
   ],
   "source": [
    "meld_s_train, meld_s_test, meld_s_val = load_train_test_val_data(\"meld_s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a941193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company 's t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must 've had your hands full .</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did . That I did .</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let 's talk a little bit about your duties .</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties ?   All right .</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>You or me ?</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1038</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>I got it . Uh , Joey , women do n't have Adam ...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1038</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>You guys are messing with me , right ?</td>\n",
       "      <td>Joey</td>\n",
       "      <td>positive</td>\n",
       "      <td>1038</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Yeah .</td>\n",
       "      <td>All</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1038</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>That was a good one . For a second there , I w...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>positive</td>\n",
       "      <td>1038</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance          Speaker  \\\n",
       "0     also I was the point person on my company 's t...         Chandler   \n",
       "1                    You must 've had your hands full .  The Interviewer   \n",
       "2                             That I did . That I did .         Chandler   \n",
       "3       So let 's talk a little bit about your duties .  The Interviewer   \n",
       "4                             My duties ?   All right .         Chandler   \n",
       "...                                                 ...              ...   \n",
       "9984                                        You or me ?         Chandler   \n",
       "9985  I got it . Uh , Joey , women do n't have Adam ...             Ross   \n",
       "9986             You guys are messing with me , right ?             Joey   \n",
       "9987                                             Yeah .              All   \n",
       "9988  That was a good one . For a second there , I w...             Joey   \n",
       "\n",
       "     Sentiment Dialogue_ID Utterance_ID  Label   Idx  \n",
       "0      neutral           0            0      1     0  \n",
       "1      neutral           0            1      1     1  \n",
       "2      neutral           0            2      1     2  \n",
       "3      neutral           0            3      1     3  \n",
       "4     positive           0            4      2     4  \n",
       "...        ...         ...          ...    ...   ...  \n",
       "9984   neutral        1038           13      1  9984  \n",
       "9985   neutral        1038           14      1  9985  \n",
       "9986  positive        1038           15      2  9986  \n",
       "9987   neutral        1038           16      1  9987  \n",
       "9988  positive        1038           17      2  9988  \n",
       "\n",
       "[9989 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meld_s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43249ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = meld_s_train[['Utterance','Sentiment']]\n",
    "test = meld_s_test[['Utterance','Sentiment']]\n",
    "val = meld_s_val[['Utterance','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0565c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"model\", exist_ok=True)\n",
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    "bert_ckpt_dir = 'model/uncased_L-12_H-768_A-12'\n",
    "bert_ckpt_file = 'model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "bert_config_file = 'model/uncased_L-12_H-768_A-12/bert_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52048236",
   "metadata": {},
   "source": [
    "# **Input Text Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9c41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    \n",
    "    text_column = \"Utterance\"\n",
    "    label_column = \"Sentiment\"\n",
    "\n",
    "    def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = 0\n",
    "        self.classes = classes\n",
    "\n",
    "        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self.prepare_data, [train, test])\n",
    "\n",
    "        print(\"max seq_len\", self.max_seq_len)\n",
    "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "        self.train_x, self.test_x = map(self.data_padding, [self.train_x, self.test_x])\n",
    "\n",
    "    def prepare_data(self, df):\n",
    "        x, y = [], []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows()):\n",
    "            text, label = row[DataPreparation.text_column], row[DataPreparation.label_column]\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "            x.append(token_ids)\n",
    "            y.append(self.classes.index(label))\n",
    "\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def data_padding(self, ids):\n",
    "        x = []\n",
    "        for input_ids in ids:\n",
    "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "            x.append(np.array(input_ids))\n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99313c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=bert_ckpt_dir+\"/vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a663c",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503d1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_defination(max_seq_len, bert_ckpt_file):\n",
    "    \n",
    "    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read())\n",
    "        bert_params = map_stock_config_to_params(bc)\n",
    "        bert_params.adapter_size = None\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "    input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "\n",
    "    print(\"bert shape\", bert_output.shape)\n",
    "\n",
    "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "    logits = keras.layers.Dropout(0.5)(logits)\n",
    "    logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
    "\n",
    "    model = keras.Model(inputs=input_ids, outputs=logits)\n",
    "    model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "    load_stock_weights(bert, bert_ckpt_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4571fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9989it [00:02, 4886.98it/s]\n",
      "C:\\Users\\gguaquiere\\anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "2610it [00:00, 4990.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 97\n"
     ]
    }
   ],
   "source": [
    "classes = train.Sentiment.unique().tolist()\n",
    "\n",
    "data = DataPreparation(train, test, tokenizer, classes, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df107e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert shape (None, 97, 768)\n",
      "Done loading 196 BERT weights from: model/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x00000248AD8819E8> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n"
     ]
    }
   ],
   "source": [
    "model = model_defination(data.max_seq_len, bert_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a2833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 97)]              0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 97, 768)           108890112 \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 2307      \n",
      "=================================================================\n",
      "Total params: 109,483,011\n",
      "Trainable params: 109,483,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5802753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(1e-5),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46716f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8990 samples, validate on 999 samples\n",
      "Epoch 1/3\n",
      "8990/8990 [==============================] - 3880s 432ms/sample - loss: 0.9765 - acc: 0.5547 - val_loss: 0.9553 - val_acc: 0.5856\n",
      "Epoch 2/3\n",
      "8990/8990 [==============================] - 3703s 412ms/sample - loss: 0.9019 - acc: 0.6415 - val_loss: 0.9096 - val_acc: 0.6306\n",
      "Epoch 3/3\n",
      "8990/8990 [==============================] - 6525s 726ms/sample - loss: 0.8581 - acc: 0.6852 - val_loss: 0.8868 - val_acc: 0.6607\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  x=data.train_x, \n",
    "  y=data.train_y,\n",
    "  validation_split=0.1,\n",
    "  batch_size=16,\n",
    "  shuffle=True,\n",
    "  epochs=3,\n",
    "  #callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcebaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
